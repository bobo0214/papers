# Transcending Forgery Specificity with Latent Space Augmentation for Generalizable Deepfake Detection

## Q0：Motivation

深度伪造检测，在面对训练数据集和测试数据集分布有差异时（数据集差异、数据量差异、数据来源差异），性能会下降。

一个合理的解释是：当面对这种情况时，检测器往往会过度拟合特定的forgery-specific artifacts，而不是学习广泛适用于各种forgery的特征。

![image-20241010141114520](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410101411613.png)

针对上述问题，论文提出的解决办法：

> enlarging the forgery space through **interpolating samples** encourages models to learn a more robust decision boundary and helps alleviate the forgery-specific overfitting.





## Q1：Architecture

![image-20241010140334746](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410101403886.png)

几种Loss之间的对比：

**real_loss:** 通过余弦相似度损失来度量（real与nt、f2f、fs、df），使模型在学习过程中更好的区分real和fake features

**deepfake_loss:** 评估二元分类器的好坏

**distallation_loss:** 结合了真实和伪造特征的损失，将Student提取的真实/伪造特征与之前Teacher提取的对应特征进行比较

**domain_loss:** 优化模型在不同领域内的分类能力（交叉熵损失），每个域一个



## Q2：Latent Space Augmentation

### Within-Domain augmentation

#### Centrifugal Transformation(离心变换)

1. challenging examples

+ 指的是距离数据集中心较远的样本，它们在训练过程中难以被分类，但包含着更丰富的信息，可以帮助模型学习到更具泛化能力的特征表示
+ 为什么难以被分类呢？
  + **特征不典型**： 这些样本的特征与数据集中心附近的样本存在较大差异，可能包含更多的异常值或噪声，导致模型难以准确地识别其类别。
  + **样本数量少**： 数据集中心附近的样本数量通常较多，而距离中心较远的样本数量较少，这可能导致模型在训练过程中无法有效地学习到这些样本的特征。
  + **类别边界模糊**： 距离数据集中心较远的样本可能位于多个类别的边界上，导致模型的决策边界难以划分。
  + **举例**：假设我们有一个包含苹果和橙子的数据集，苹果和橙子分别位于数据集的两端。那么，距离数据集中心较远的样本可能是苹果和橙子的混合体，或者是一些形状和颜色不典型的水果。这些样本的特征与苹果和橙子都存在较大差异，导致模型难以准确地判断其类别。
+ 为什么提出？
  + **扩大特征空间**： challenging examples 通常距离数据集中心较远，它们包含着更丰富的信息，可以帮助模型学习到更全面的特征表示，从而扩大模型的特征空间。
  + **避免过拟合**： challenging examples 可以帮助模型避免过拟合于特定的伪造特征，从而提高模型的泛化能力。
  + **学习更具区分性的特征**： challenging examples 通常位于多个类别的边界上，它们可以帮助模型学习到更具区分性的特征，从而提高模型的分类精度。

2. 获取challenging examples的方法

+ **直接方法**：将样本沿着远离数据集中心的离心方向进行变换

  + domain centroid：

    ![image-20241010202220190](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410102022305.png)

  + ![image-20241010202258812](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410102022869.png)

+ **间接方法**：将样本向已有的 challenging examples 推动进行变换

  + ![image-20241010202407842](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410102024922.png)



#### Affine Transformation(仿射变换)

+ **目标**： 通过**旋转** Student module 提取的伪造人脸特征，使模型能够学习到更具鲁棒性的特征表示。

+ **仿射旋转矩阵A**：

  ![image-20241010202903417](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410102029485.png)

+ **方法**：

  1. **计算旋转矩阵**： 根据随机采样得到的旋转角度 θ，计算对应的仿射旋转矩阵 A。
  2. **提取特征位置信息**： 从 Student module 提取的伪造人脸特征中提取出每个元素的位置信息 P。
  3. **旋转特征**： 将旋转矩阵 A 与位置信息 P 相乘，得到旋转后的位置信息 P̂。
  4. **重排元素位置**： 根据旋转后的位置信息 P̂，将特征图中的元素重新排列，得到旋转后的特征图。



#### Additive Transformation(加法变换)

+ **目标**： 通过向 Student module 提取的伪造人脸特征**添加噪声**，使模型能够学习到更具鲁棒性的特征表示。

+ **方法**：

  1. **生成噪声**： 使用高斯混合模型生成噪声向量 ϵ，其均值为 0，协方差矩阵为 Σ。
  2. **添加噪声**： 将噪声向量 ϵ 与 Student module 提取的伪造人脸特征进行相加，得到添加噪声后的特征。

  ![image-20241010210328725](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410102103797.png)



### Cross-Domain augmentation

+ **目标**： 通过将不同伪造类型内部的特征进行混合，使模型能够学习到更具泛化能力的特征表示，从而更好地识别不同伪造类型之间的边界。

+ **方法**：

  1. **选择特征**： 从两个不同伪造类型内部随机选择两个特征向量
  2. **线性组合**： 将这两个特征向量进行线性组合，得到一个新的特征向量 
  3. **应用 Mixup**： 使用 Mixup 技术将这个新的特征向量与其他特征向量进行混合，得到最终的增强特征。

  ![image-20241010210706216](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410102107276.png)



## 补充

### 1. 蒸馏模型

> 蒸馏模型（Model Distillation）是一种深度学习模型压缩技术，主要目的是将**大模型**中的知识提取并迁移到一个**小模型**中，使得小模型在保持性能的前提下，能够显著降低计算开销和内存需求。这种技术最早由Geoffrey Hinton等人在2015年提出，用于将复杂模型的知识“蒸馏”给更简单的模型。
>
> ### 核心思想
>
> 知识蒸馏的基本思想是让小模型（称为**学生模型**，Student Model）通过学习大模型（称为**教师模型**，Teacher Model）的输出来提升其性能。教师模型通常是一个大型的、复杂的模型（如深度的神经网络或集成模型），而学生模型则是一个较小的模型，计算效率更高。
>
> ### 蒸馏过程
>
> 1. **训练教师模型**：首先训练一个性能优异的、复杂的大模型作为教师模型。教师模型可以是深度神经网络、集成模型等。
>
> 2. **获取教师模型的软标签**：
>
>    - 教师模型的输出通常不仅仅是类别标签，而是包括类别概率的**软标签**。这些软标签包含了更多的关于类别之间关系的信息，而不仅仅是硬分类结果。
>
>    - 通常使用温度参数 $T$ 来调整输出的概率分布，使其更加“软”，有助于学生模型的学习。温度参数 $T$ 在Softmax函数中使用：
>
>      $pi= \frac{\exp(z_i / T)}{\sum_j \exp(z_j / T)}$
>
>      其中，$z_i$ 是教师模型的输出， $T$ 是温度参数。当 $T$ 增大时，输出的概率分布更加平滑。
>
> 3. **训练学生模型**：
>
>    - 学生模型通过模仿教师模型的输出进行训练。它不仅学习教师模型的软标签，还可以结合传统的交叉熵损失，直接对真实标签进行监督学习。
>
>    - 最终损失函数可能由两部分组成：
>
>      1. 模仿教师模型的软标签损失（蒸馏损失）
>      2. 学习真实标签的传统分类损失
>
>      损失函数可以表示为：
>
>      $L= (1 - \alpha) L_{\text{CE}}(y, p_{\text{student}}) + \alpha L_{\text{KD}}(p_{\text{teacher}}, p_{\text{student}})$
>
>      其中 $L_{\text{CE}}$ 是交叉熵损失，$L_{\text{KD}}$ 是知识蒸馏损失， $α$ 是用于平衡这两个损失的权重。
>
> ### 优势
>
> 1. **模型压缩**：蒸馏模型可以大幅度压缩模型的参数量，使得小模型能够在移动设备或嵌入式设备上运行。
> 2. **推理速度加快**：小模型计算量小，推理速度更快，适用于实时或资源有限的场景。
> 3. **保持性能**：尽管学生模型较小，但由于学习了教师模型的知识，它往往可以达到与教师模型接近的性能。
> 4. **泛化能力提升**：蒸馏过程中，学生模型学习的不仅仅是数据标签，还学习了教师模型在整个数据分布中的细粒度知识，这有助于学生模型的泛化能力。
>
> ### 总结
>
> 蒸馏模型是一种有效的模型压缩技术，通过让小模型模仿大模型的行为，从而在计算资源有限的情况下保持良好的性能。它能够降低推理时间和内存消耗，是深度学习模型部署中的重要技术之一。



### 2. 仿射变换 Affine Transformation

> 仿射变换 (Affine Transformation) 是一种线性变换，它可以将一个二维或三维图形进行平移、旋转、缩放、翻转等操作，同时保持图形的直线性和平行性。
>
> **仿射变换的数学表达**：
>
> 二维仿射变换可以用一个 3x3 的矩阵表示，如下所示：
>
> ```
> [ x' ]   [ a11  a12  tx ]   [ x ]
> [ y' ] = [ a21  a22  ty ] * [ y ]
> [ 1  ]   [ 0    0    1  ]   [ 1 ]
> ```
>
> 其中，(x, y) 是原始图形上的一个点，(x', y') 是经过仿射变换后的点，矩阵中的 a11, a12, a21, a22, tx, ty 分别代表缩放、旋转、平移等变换参数。
>
> **仿射变换的类型**：
>
> - **平移 (Translation)**: 将图形沿着 x 轴或 y 轴移动一定的距离。
> - **旋转 (Rotation)**: 将图形绕着原点或指定的中心点旋转一定的角度。
> - **缩放 (Scaling)**: 将图形沿着 x 轴或 y 轴进行放大或缩小。
> - **翻转 (Reflection)**: 将图形沿着 x 轴或 y 轴进行翻转。
> - **剪切 (Shear)**: 将图形沿着 x 轴或 y 轴进行倾斜。