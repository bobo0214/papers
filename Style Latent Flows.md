# Exploiting Style Latent Flows for Generalizing Deepfake Video Detection

## Q1：deepfake 检测框架

![image-20241009200845753](https://raw.githubusercontent.com/bobo0214/typora_pic/main/img/202410092008882.png)

### 1. StyleGRU module

+ **输入**：

  + $I_p$：原视频片段 $I$ 经过FFHQ预处理得到的由cropped face组成的视频片段，调整大小为$R^{256×256×l}$（ $l$ 是原视频片段的连续帧数）

+ **Style latent vectors的提取**：

  + 使用 **pSp 编码器**从视频帧中提取风格潜向量
    + pSp 编码器是一种专门针对 StyleGAN 潜空间设计的编码器，它能够将图像编码为风格潜向量，并保留图像的视觉特征。
  +  $  \mathbf {S} = pSp(I_{p}) \equiv \{s_{1}, s_{2}, ..., s_{l}\}$
    + $s_{1}, s_{2}, ..., s_{l}$ ：对应每帧提起的风格潜向量

+ **Style flow的计算**:

  + 将连续帧的<u>风格潜向量</u>进行差分，得到**风格流** 
    + 风格流反映了风格潜变量在时间上的变化，包含了视频的动态信息，例如面部表情和几何变换的变化
  + 风格流 $   \Delta \mathbf {S} = \{\Delta s_{1}, \Delta s_{2}, ..., \Delta s_{(l-1)}\}$
    + 其中 $∆s_i = s_{i+1} − s_i$

+ **GRU编码**

  + 将风格流 $\Delta \mathbf {S}$ 作为<font color='pink'>GRU</font>的输入
    + GRU 是一种循环神经网络，能够捕捉序列数据的时序特征。
    + 通过 GRU 的循环结构，可以有效地学习风格流的动态变化。
  + GRU 的最后一个隐藏状态包含了对风格流动态变化的完整编码，作为风格时间特征 $E_{style}$
    + 通过pSp编码器提取的风格特征向量是GAN反演任务的特征，因此不足以直接应用于深度伪造检测任务
    + $E_{style}$ 是一个向量，**包含了风格潜变量在时间上的变化信息**，可以作为深度伪造检测的依据
  +  $ E_{\text {style}} = \mathbf {GRU}(\Delta \mathbf {S})$

  

### 2. 3D ResNet-50 module

+ **输入**：

  + $I$：原视频片段，调整大小为$R^{224×224×l}$

+ **提取视频内容特征 $C_{content}$**

  +  $C_{content}$：组合了视频帧的视觉和时序特征
  + $C_{\text {content}} = \mathbf {3D~CNN}(I))$

  

### 3. Style attention module

- 该模块将 StyleGRU 生成的风格时间特征 E*style 与内容特征 C*content 结合，以增强对视觉和时序伪影的检测。
- 使用注意力机制，将 E*style 作为查询，C*content 作为键和值，通过计算风格注意力分数，加权组合特征。
- 最终，得到加权后的特征向量，用于后续的深度伪造检测。

### 4. Temporal transformer encoder module

- 该模块将 SAM 输出的特征向量映射到二进制类别（真实/伪造）。
- 使用标准的 Transformer 编码器块，通过多头自注意力机制和多层感知器学习特征表示。
- 最终，TTE 输出经过 sigmoid 函数处理的概率值，表示输入视频为真实或伪造。



## Q2：训练过程

### Stage 1: style representation learning

- 阶段 1：风格表示学习：
  - 使用对比学习技术训练 StyleGRU 模块，学习风格流的有效表示。
  - 使用三元组损失和分类损失训练 GRU，使其能够区分真实和伪造视频的风格流。

### Stage 2: style attention-based deepfake detection

+ 阶段 2：基于风格注意力机制的深度伪造检测：

- 使用二元交叉熵损失训练 3D ResNet-50、SAM 和 TTE 模块，完成真实/伪造的二分类任务。
- 将训练好的 StyleGRU 模块固定，用于提取风格时间特征。



## 补充

### 1. Disentangled latent space

> 解耦的潜在空间：这指的是GAN模型（特别是StyleGAN）能够生成一个结构良好的潜在空间。在这个潜在空间中，图像的不同特征（如姿势、发型、表情等）可以**独立**地控制和调整。

### 2. GAN inversion

> **GAN反演**是一个技术流程，其目标是找到一个潜在代码（latent code），这个代码能够在GAN的潜在空间中生成与目标图像非常相似的图像。简单来说，就是通过逆向操作找到可以生成给定图像的潜在表示。
>
> ### 1. 预训练的GAN模型
>
> 首先，需要一个预训练好的GAN模型，比如StyleGAN或BigGAN。这些模型已经学习到从潜在空间生成高质量图像的映射关系。
>
> ### 2. 潜在空间
>
> GAN的潜在空间通常是一个高维空间，输入到生成器的潜在向量（如 $z$ 或 $w$ 向量）能够控制生成图像的特征。
>
> ### 3. 图像输入
>
> 选择一张需要反演的真实图像$I$。我们的目标是找到一个潜在向量 $z^*$，使得生成器能够生成与图像 $I$ 尽可能相似的图像 $G(z^*)$。
>
> ### 4. 优化过程
>
> 使用优化算法（如梯度下降）来迭代地调整潜在向量 $z$。具体步骤如下：
>
> - **损失函数**：定义一个损失函数来衡量生成图像与输入图像之间的相似度，通常使用L2损失或感知损失（perceptual loss）。
>
>   $L(z)= \| G(z) - I \|^2$
>
> - **反向传播**：通过计算损失函数的梯度，更新潜在向量 $z$。
>
> ### 5. 迭代优化
>
> 重复步骤4，直到损失函数收敛，找到使生成图像与输入图像相似的最佳潜在向量 $z^*$。
>
> ### 6. 输出结果
>
> 完成优化后，得到的潜在向量 $z^*$ 可以用来分析或修改图像属性，或者用于其他应用，如图像编辑、风格迁移等。



> **编码器encoders**在GAN反演中的作用：
>
> 1. **图像到潜在空间的映射**：
>
>    - 编码器的主要功能是将输入的真实图像 $I$ 转换为潜在向量$z$。这一过程也被称为“编码”或“反演”。
>
>    - 通过学习特征表示，编码器能够有效捕捉图像的关键信息，并将其压缩成潜在空间中的向量。
>
> 2. **快速估计**：
>    - 编码器可以快速地为任意图像提供一个潜在向量，减少了对潜在向量的直接优化过程。这样可以加快反演的速度。
>
> 3. **学习到的映射**：
>
>    - 在某些情况下，编码器是**经过训练的模型**（例如，Autoencoder或基于GAN的编码器），它学习了如何将输入映射到潜在空间。
>
>    
>
> **解码器decoders**在GAN反演中的作用：
>
> 1. **潜在向量到图像的生成**：
>
>    - 解码器的作用是从潜在向量 $z$ 生成图像 $G(z)$。它通常是GAN生成器的部分。
>
>    - 解码器通过将潜在向量转换为高维图像，确保生成的图像在视觉上与输入图像相似。
>
> 2. **重构图像**：
>    - 在反演过程中，解码器用于将编码器生成的潜在向量转换为图像。这一过程是通过优化潜在向量来不断调整生成的图像，使其与原始图像更相似。



### 3. GRU

> GRU（Gated Recurrent Unit）是一种循环神经网络（RNN）的变体，它通过引入**门控机制**来提高 RNN 的效率和性能。
>
> **1. 循环神经网络（RNN）**：
>
> - RNN 是一种神经网络，用于处理序列数据，例如时间序列、文本数据等。
> - RNN 的基本思想是将当前输入与之前的信息结合起来，生成当前的输出。
>
> **2. 门控机制**：
>
> - GRU 通过门控机制来控制信息在 RNN 中的流动。
> - 门控机制包括：
>   - **重置门（Reset Gate）**：控制当前输入信息对 RNN 状态的影响。
>     - 根据当前输入和上一个 RNN 状态，决定**是否**更新 RNN 状态。
>   - **更新门（Update Gate）**：控制 RNN 状态的更新。
>     - 根据当前输入和上一个 RNN 状态，决定**如何**更新 RNN 状态。
>   - **输出门（Output Gate）**：控制 RNN 输出的信息。
>     - 根据当前输入、上一个 RNN 状态和更新后的 RNN 状态，决定如何生成当前输出。
>
> **3. 优点**：
>
> - 与传统的 RNN 相比，GRU 具有以下优点：
>   - **效率更高**：GRU 的结构比 RNN 简单，计算量更小，训练速度更快。
>   - **更易于训练**：GRU 的门控机制可以有效地控制信息流动，使得 RNN 更容易训练。
>   - **更适用于长序列**：GRU 能够更好地捕捉长序列中的长期依赖关系。
>
> **4. 应用场景**：
>
> - GRU 可以应用于各种序列数据处理任务，例如：
>   - **自然语言处理**：例如文本分类、机器翻译、情感分析等。
>   - **语音识别**：例如语音转文字、语音合成等。
>   - **时间序列分析**：例如股票价格预测、天气预报等。



### 4. 3D ResNet-50

> **1. 模型结构**：
>
> - 3D ResNet-50 模型是基于 2D ResNet-50 模型扩展而来的。
> - 2D ResNet-50 模型是一个经典的图像分类模型，它由多个残差块组成，每个残差块包含多个卷积层和池化层。
> - 3D ResNet-50 模型将 2D ResNet-50 模型的卷积层扩展为 3D 卷积层，使得模型能够处理视频帧的三维数据（时间维度、空间维度）。
>
> **2. 3D 卷积层**：
>
> - 3D 卷积层与 2D 卷积层类似，但它能够同时处理时间维度和空间维度上的信息。
> - 3D 卷积层可以提取视频帧的时空特征，例如：
>   - **时间特征**：例如运动轨迹、速度、加速度等。
>   - **空间特征**：例如纹理、形状、颜色等。
>
> **3. 残差块**：
>
> - 3D ResNet-50 模型包含多个残差块，每个残差块包含多个 3D 卷积层和激活函数。
> - 残差块的结构与 2D ResNet-50 模型类似，但它使用 3D 卷积层和 3D 池化层。
> - 残差块能够有效地学习视频帧的复杂特征，并通过残差连接避免梯度消失问题。
>
> **4. 全局平均池化**：
>
> - 在 3D ResNet-50 模型的最后一个残差块之后，使用全局平均池化将特征图压缩为一个特征向量。
> - 全局平均池化能够有效地提取视频帧的特征，并减少模型参数量。
>
> **5. 内容特征**：
>
> - 3D ResNet-50 模型的输出是一个特征向量，包含了视频帧的视觉和时序特征，称为内容特征 C_content。
> - 内容特征 C_content 可以用于深度伪造检测，例如：
>   - **检测视觉伪影**：例如颜色失真、纹理不一致等。
>   - **检测时序伪影**：例如运动不自然、时间跳跃等。